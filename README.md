# MultiplicaciÃ³n de Matrices Paralela con Procesos

Programa en C++ que implementa multiplicaciÃ³n de matrices optimizada usando **procesos** y **optimizaciÃ³n por bloques** (blocking/tiling). Incluye anÃ¡lisis de rendimiento con la **Ley de Amdahl**.

## âš¡ Quick Start (FÃCIL - Sin instalar nada)

### ğŸ§ Linux / ğŸ macOS

**OpciÃ³n 1: Compilar y ejecutar automÃ¡ticamente (MÃS SIMPLE)**

```bash
./run.sh
```

Ese Ãºnico comando:
- âœ… Detecta tu sistema operativo
- âœ… Verifica que tengas g++ instalado
- âœ… Compila todo automÃ¡ticamente
- âœ… Pregunta si quieres ejecutar

**OpciÃ³n 2: Solo compilar (sin ejecutar)**

```bash
./compile.sh
./matrix_mult
```

**Â¿No tienes g++ instalado?** Sigue las instrucciones que aparecerÃ¡n en pantalla.

---

### ğŸªŸ Windows

**âš ï¸ IMPORTANTE:** El programa usa `fork()` que NO existe nativamente en Windows. Tienes 3 opciones:

**1ï¸âƒ£ WSL (Recomendada - Funciona al 100%)**
```bash
wsl --install        # En PowerShell como Administrador
# Luego, dentro de WSL:
./run.sh
```

**2ï¸âƒ£ Git Bash (Simple pero limitado)**
```bash
./run.sh             # Abre Git Bash en la carpeta
```

**3ï¸âƒ£ CMD nativo (Con limitaciones serias)**
```cmd
run.bat              # Compila pero SIN paralelizaciÃ³n real
matrix_mult.exe
```

ğŸ“– **Instrucciones detalladas:** Lee `INSTRUCCIONES_WINDOWS.txt`

### Otras opciones (si ya conoces make/cmake):

<details>
<summary>Haz clic aquÃ­ para ver opciones avanzadas</summary>

**Con Makefile (Linux/macOS):**
```bash
make
./matrix_mult
```

**Con CMake (multiplataforma):**
```bash
mkdir build && cd build
cmake ..
cmake --build .
./matrix_mult
```
</details>

## ğŸš€ CaracterÃ­sticas

- âœ… **MultiplicaciÃ³n optimizada por bloques**: Aprovecha la localidad de cachÃ© (5-20x mÃ¡s rÃ¡pido)
- âœ… **ParalelizaciÃ³n con procesos**: Usa `fork()` en Linux/macOS (mejor que hilos para este caso)
- âœ… **DetecciÃ³n automÃ¡tica de hardware**: NÃºcleos, cachÃ©, SO
- âœ… **AnÃ¡lisis de Amdahl**: Calcula fracciÃ³n paralelizable (f) empÃ­ricamente
- âœ… **Benchmark completo**: Prueba con 1, 2, 4, 8, ..., P_max procesos
- âœ… **Multiplataforma**: Compatible con Linux, macOS, Windows

## ğŸ“‹ Requisitos MÃ­nimos

Solo necesitas:
- **g++** instalado (compilador de C++)
- **Linux** o **macOS** (Windows tiene limitaciones en paralelizaciÃ³n)

**Â¿No tienes g++?**

```bash
# Ubuntu/Debian/ZorinOS
sudo apt-get update && sudo apt-get install build-essential

# macOS
xcode-select --install
```

**El script `./run.sh` detectarÃ¡ automÃ¡ticamente si falta g++ y te dirÃ¡ quÃ© comando ejecutar.**

## ğŸ“– Uso

### MenÃº Principal

```
========================================
    MULTIPLICACION DE MATRICES EN C++
    Procesos + Optimizacion por Bloques
========================================
1. Mostrar informacion del hardware
2. Ejecutar multiplicacion SECUENCIAL
3. Ejecutar multiplicacion PARALELA (P_max)
4. Ejecutar BENCHMARK COMPLETO (comparacion)
5. Configurar tamanio de matrices
6. Mostrar configuracion actual
7. Salir
========================================
```

### Opciones Explicadas

#### 1. Mostrar informaciÃ³n del hardware

Muestra:
- Sistema operativo
- Modelo de CPU
- NÃºcleos lÃ³gicos y fÃ­sicos
- TamaÃ±os de cachÃ© (L1, L2, L3)
- TamaÃ±o de bloque Ã³ptimo calculado

#### 2. MultiplicaciÃ³n SECUENCIAL

- Ejecuta una sola vez con 1 proceso (P=1)
- Muestra tabla con tiempo y GFLOPS
- Usa optimizaciÃ³n por bloques

#### 3. MultiplicaciÃ³n PARALELA

- Ejecuta con el mÃ¡ximo de procesos disponibles (P_max)
- Compara contra tiempo secuencial
- Muestra speedup experimental

#### 4. BENCHMARK COMPLETO

- Ejecuta mÃºltiples veces: P = 1, 2, 4, 8, ..., P_max
- Genera 2 tablas:
  1. **Tabla Secuencial** (P=1)
  2. **Tabla Paralela** (comparaciÃ³n de todos los P)
- Calcula:
  - FracciÃ³n paralelizable (f) empÃ­ricamente
  - Speedup experimental vs. Speedup teÃ³rico (Amdahl)
  - Eficiencia
  - Granularidad (Gruesa/Media/Fina)
  - Speedup mÃ¡ximo teÃ³rico
- **Exporta automÃ¡ticamente** los resultados a `benchmark_results.csv` para graficaciÃ³n

#### 5. Configurar tamaÃ±o de matrices

- Permite cambiar el tamaÃ±o de las matrices (NxN)
- Rango vÃ¡lido: 10 a 10000

#### 6. Mostrar configuraciÃ³n actual

- TamaÃ±o de matriz
- TamaÃ±o de bloques (auto-optimizado)
- NÃºmero mÃ¡ximo de procesos
- NÃºcleos disponibles

## ğŸ“Š VisualizaciÃ³n de Resultados

### Generar GrÃ¡ficas

DespuÃ©s de ejecutar el **BENCHMARK COMPLETO** (opciÃ³n 4), se genera automÃ¡ticamente el archivo `benchmark_results.csv`. Para visualizar los resultados:

```bash
python3 plot_results.py
```

Este script genera 5 grÃ¡ficas PNG:

1. **grafica_speedup.png** - Speedup vs Procesos (Experimental vs TeÃ³rico vs Ideal)
2. **grafica_eficiencia.png** - Eficiencia vs Procesos (con umbrales de granularidad)
3. **grafica_tiempo.png** - Tiempo de EjecuciÃ³n vs Procesos
4. **grafica_gflops.png** - Rendimiento (GFLOPS) vs Procesos
5. **grafica_resumen.png** - Panel con las 4 grÃ¡ficas principales

### Requisitos para GraficaciÃ³n

```bash
# Instalar dependencias de Python (si no estÃ¡n instaladas)
pip3 install pandas matplotlib numpy

# O usando conda
conda install pandas matplotlib numpy
```

**Nota:** Las grÃ¡ficas se guardan automÃ¡ticamente como archivos PNG de alta resoluciÃ³n (300 DPI).

## ğŸ“Š Ejemplo de Salida

### InformaciÃ³n del Hardware

```
========================================
    INFORMACION DEL HARDWARE
========================================
Sistema Operativo:         Linux
Modelo de CPU:             Intel Core i7-9700K
Nucleos Logicos:           8
Nucleos Fisicos (est.):    8
Cache L1:                  32.00 KB
Cache L2:                  256.00 KB
Cache L3:                  12.00 MB
Tamanio de bloque optimo:  64x64
========================================
```

### Tabla de Benchmark Completo

```
========================================
    TABLA PARALELA - COMPARACION
========================================
| Procesos   | Tiempo (s)   | Speedup Exp | Speedup Amdahl | Eficiencia   | Granularidad |
| 1          | 2.345600     | 1.00x       | 1.00x          | 100.0%       | N/A          |
| 2          | 1.210300     | 1.94x       | 1.96x          | 97.0%        | Gruesa       |
| 4          | 0.645200     | 3.64x       | 3.77x          | 91.0%        | Media        |
| 8          | 0.312100     | 7.52x       | 7.02x          | 94.0%        | Fina         |
========================================

========================================
    FRACCION PARALELIZABLE (f)
========================================
f (teorico asumido):       0.980 (98.0% paralelizable)
f (empirico medido):       0.973 (97.3% paralelizable)
Metodo usado:              Calculado de S(2) experimental
========================================

========================================
    ANALISIS FINAL
========================================
Mejor speedup observado:        7.52x con 8 procesos
Speedup maximo teorico (Amdahl): 37.04x (P->infinito)
Limitacion por codigo secuencial: 2.7%
========================================
```

## ğŸ§® Conceptos TÃ©cnicos

### OptimizaciÃ³n por Bloques (Blocking/Tiling)

En lugar de multiplicar matrices elemento por elemento:

```
C[i][j] = Î£ A[i][k] * B[k][j]
```

Se dividen en bloques pequeÃ±os que caben en cachÃ© L1:

```
Para cada bloque de C:
  Cargar bloque de A en cachÃ©
  Cargar bloque de B en cachÃ©
  Calcular bloque de C
```

**Ventajas:**
- Reduce cache misses de ~90% a ~10%
- Mejora hasta 20x en rendimiento
- TamaÃ±o de bloque calculado automÃ¡ticamente segÃºn cachÃ© L1

### Ley de Amdahl

La fracciÃ³n paralelizable (f) determina el speedup mÃ¡ximo:

```
S(P) = 1 / ((1-f) + f/P)
S_max = 1 / (1-f)
```

**Ejemplo:**
- Si f = 0.95 (95% paralelizable, 5% secuencial)
- Speedup mÃ¡ximo = 1/0.05 = 20x (incluso con infinitos procesos)

El programa calcula **f empÃ­ricamente** usando la mediciÃ³n con P=2:

```
f = 2 * (1 - 1/S(2))
```

### Granularidad

Indica el balance entre cÃ³mputo y comunicaciÃ³n:

- **Gruesa** (Eficiencia > 80%): Poco overhead, mucho cÃ³mputo
- **Media** (50% < Eficiencia â‰¤ 80%): Balance
- **Fina** (Eficiencia â‰¤ 50%): Mucho overhead, poco cÃ³mputo

## ğŸ“ Estructura del Proyecto

```
proyecto/
â”œâ”€â”€ include/
â”‚   â”œâ”€â”€ Config.h                # Constantes y estructuras
â”‚   â”œâ”€â”€ HardwareDetector.h      # DetecciÃ³n de hardware
â”‚   â”œâ”€â”€ MatrixMultiplier.h      # MultiplicaciÃ³n optimizada
â”‚   â”œâ”€â”€ ProcessManager.h        # GestiÃ³n de procesos
â”‚   â”œâ”€â”€ PerformanceAnalyzer.h   # AnÃ¡lisis de rendimiento
â”‚   â”œâ”€â”€ SharedMemory.h          # Memoria compartida (IPC)
â”‚   â””â”€â”€ Utils.h                 # Utilidades
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.cpp                # Programa principal
â”‚   â”œâ”€â”€ HardwareDetector.cpp
â”‚   â”œâ”€â”€ MatrixMultiplier.cpp
â”‚   â”œâ”€â”€ ProcessManager.cpp
â”‚   â”œâ”€â”€ PerformanceAnalyzer.cpp
â”‚   â”œâ”€â”€ SharedMemory.cpp
â”‚   â””â”€â”€ Utils.cpp
â”‚
â”œâ”€â”€ Makefile                    # CompilaciÃ³n (Linux/macOS)
â”œâ”€â”€ CMakeLists.txt              # CompilaciÃ³n (multiplataforma)
â”œâ”€â”€ plot_results.py             # Script Python para graficaciÃ³n
â”œâ”€â”€ benchmark_results.csv       # Resultados exportados (generado)
â””â”€â”€ README.md                   # Este archivo
```

## ğŸ› SoluciÃ³n de Problemas

### Error: "No se pudo crear memoria compartida"

**Causa:** LÃ­mites del sistema para memoria compartida.

**SoluciÃ³n (Linux):**
```bash
# Ver lÃ­mites actuales
ipcs -lm

# Aumentar lÃ­mite (como root)
sudo sysctl -w kernel.shmmax=1073741824
sudo sysctl -w kernel.shmall=268435456
```

### Error de compilaciÃ³n: "pthread.h not found"

**SoluciÃ³n:**
```bash
# Ubuntu/Debian
sudo apt-get install build-essential

# macOS (instalar Xcode Command Line Tools)
xcode-select --install
```

### El programa se bloquea en paralelo

**Causa:** Procesos hijos no terminan correctamente.

**SoluciÃ³n:** Verificar que no hay procesos zombies:
```bash
ps aux | grep matrix_mult
killall -9 matrix_mult
```

## ğŸ“ Notas

- El tamaÃ±o de bloque se calcula automÃ¡ticamente segÃºn el cachÃ© L1 de tu CPU
- En Windows, la implementaciÃ³n paralela tiene limitaciones (usa CreateProcess en lugar de fork)
- Para matrices muy grandes (>5000x5000), considera aumentar la memoria compartida del sistema
- Los mejores resultados se obtienen con matrices de tamaÃ±o mÃºltiplo del tamaÃ±o de bloque

## ğŸ‘¨â€ğŸ’» Autor

Proyecto desarrollado para el curso de ProgramaciÃ³n Paralela.

## ğŸ“„ Licencia

Este proyecto es de cÃ³digo abierto para fines educativos.
