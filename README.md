# Multiplicaci√≥n de Matrices Paralela con Procesos

Programa en C++ que implementa multiplicaci√≥n de matrices optimizada usando **procesos** y **optimizaci√≥n por bloques** (blocking/tiling). Incluye an√°lisis de rendimiento con la **Ley de Amdahl**.

## ‚ö° Quick Start (F√ÅCIL - Sin instalar nada)

### üêß Linux / üçé macOS

**Opci√≥n 1: Compilar y ejecutar autom√°ticamente (M√ÅS SIMPLE)**

```bash
./run.sh
```

Ese √∫nico comando:
- ‚úÖ Detecta tu sistema operativo
- ‚úÖ Verifica que tengas g++ instalado
- ‚úÖ Compila todo autom√°ticamente
- ‚úÖ Pregunta si quieres ejecutar

**Opci√≥n 2: Solo compilar (sin ejecutar)**

```bash
./compile.sh
./matrix_mult
```

**¬øNo tienes g++ instalado?** Sigue las instrucciones que aparecer√°n en pantalla.

---

### ü™ü Windows

**‚ö†Ô∏è IMPORTANTE:** El programa usa `fork()` que NO existe nativamente en Windows. Tienes 3 opciones:

**1Ô∏è‚É£ WSL (Recomendada - Funciona al 100%)**
```bash
wsl --install        # En PowerShell como Administrador
# Luego, dentro de WSL:
./run.sh
```

**2Ô∏è‚É£ Git Bash (Simple pero limitado)**
```bash
./run.sh             # Abre Git Bash en la carpeta
```

**3Ô∏è‚É£ CMD nativo (Con limitaciones serias)**
```cmd
run.bat              # Compila pero SIN paralelizaci√≥n real
matrix_mult.exe
```

üìñ **Instrucciones detalladas:** Lee `INSTRUCCIONES_WINDOWS.txt`

### Otras opciones (si ya conoces make/cmake):

<details>
<summary>Haz clic aqu√≠ para ver opciones avanzadas</summary>

**Con Makefile (Linux/macOS):**
```bash
make
./matrix_mult
```

**Con CMake (multiplataforma):**
```bash
mkdir build && cd build
cmake ..
cmake --build .
./matrix_mult
```
</details>

## üöÄ Caracter√≠sticas

- ‚úÖ **Multiplicaci√≥n optimizada por bloques**: Aprovecha la localidad de cach√© (5-20x m√°s r√°pido)
- ‚úÖ **Paralelizaci√≥n con procesos**: Usa `fork()` en Linux/macOS (mejor que hilos para este caso)
- ‚úÖ **Detecci√≥n autom√°tica de hardware**: N√∫cleos, cach√©, SO
- ‚úÖ **An√°lisis de Amdahl**: Calcula fracci√≥n paralelizable (f) emp√≠ricamente
- ‚úÖ **Benchmark completo**: Prueba con 1, 2, 4, 8, ..., P_max procesos
- ‚úÖ **Multiplataforma**: Compatible con Linux, macOS, Windows

## üìã Requisitos M√≠nimos

Solo necesitas:
- **g++** instalado (compilador de C++)
- **Linux** o **macOS** (Windows tiene limitaciones en paralelizaci√≥n)

**¬øNo tienes g++?**

```bash
# Ubuntu/Debian/ZorinOS
sudo apt-get update && sudo apt-get install build-essential

# macOS
xcode-select --install
```

**El script `./run.sh` detectar√° autom√°ticamente si falta g++ y te dir√° qu√© comando ejecutar.**

## üìñ Uso

### Men√∫ Principal

```
========================================
    MULTIPLICACION DE MATRICES EN C++
    Procesos + Optimizacion por Bloques
========================================
1. Mostrar informacion del hardware
2. Ejecutar multiplicacion SECUENCIAL
3. Ejecutar multiplicacion PARALELA (P_max)
4. Ejecutar BENCHMARK COMPLETO (comparacion)
5. Configurar tamanio de matrices
6. Mostrar configuracion actual
7. Salir
========================================
```

### Opciones Explicadas

#### 1. Mostrar informaci√≥n del hardware

Muestra:
- Sistema operativo
- Modelo de CPU
- N√∫cleos l√≥gicos y f√≠sicos
- Tama√±os de cach√© (L1, L2, L3)
- Tama√±o de bloque √≥ptimo calculado

#### 2. Multiplicaci√≥n SECUENCIAL

- Ejecuta una sola vez con 1 proceso (P=1)
- Muestra tabla con tiempo y GFLOPS
- Usa optimizaci√≥n por bloques

#### 3. Multiplicaci√≥n PARALELA

- Ejecuta con el m√°ximo de procesos disponibles (P_max)
- Compara contra tiempo secuencial
- Muestra speedup experimental

#### 4. BENCHMARK COMPLETO

- Ejecuta m√∫ltiples veces: P = 1, 2, 4, 8, ..., P_max
- Genera 2 tablas:
  1. **Tabla Secuencial** (P=1)
  2. **Tabla Paralela** (comparaci√≥n de todos los P)
- Calcula:
  - Fracci√≥n paralelizable (f) emp√≠ricamente
  - Speedup experimental vs. Speedup te√≥rico (Amdahl)
  - Eficiencia
  - Granularidad (Gruesa/Media/Fina)
  - Speedup m√°ximo te√≥rico
- **Exporta autom√°ticamente** los resultados a `benchmark_results.csv` para graficaci√≥n

#### 5. Configurar tama√±o de matrices

- Permite cambiar el tama√±o de las matrices (NxN)
- Rango v√°lido: 10 a 10000

#### 6. Mostrar configuraci√≥n actual

- Tama√±o de matriz
- Tama√±o de bloques (auto-optimizado)
- N√∫mero m√°ximo de procesos
- N√∫cleos disponibles

## üìä Visualizaci√≥n de Resultados

### Generar Gr√°ficas

Despu√©s de ejecutar el **BENCHMARK COMPLETO** (opci√≥n 4), se genera autom√°ticamente el archivo `benchmark_results.csv`. Para visualizar los resultados:

```bash
python3 plot_results.py
```

Este script genera 5 gr√°ficas PNG:

1. **grafica_speedup.png** - Speedup vs Procesos (Experimental vs Te√≥rico vs Ideal)
2. **grafica_eficiencia.png** - Eficiencia vs Procesos (con umbrales de granularidad)
3. **grafica_tiempo.png** - Tiempo de Ejecuci√≥n vs Procesos
4. **grafica_gflops.png** - Rendimiento (GFLOPS) vs Procesos
5. **grafica_resumen.png** - Panel con las 4 gr√°ficas principales

### Requisitos para Graficaci√≥n

```bash
# Instalar dependencias de Python (si no est√°n instaladas)
pip3 install pandas matplotlib numpy

# O usando conda
conda install pandas matplotlib numpy
```

**Nota:** Las gr√°ficas se guardan autom√°ticamente como archivos PNG de alta resoluci√≥n (300 DPI).

## üìä Ejemplo de Salida

### Informaci√≥n del Hardware

```
========================================
    INFORMACION DEL HARDWARE
========================================
Sistema Operativo:         Linux
Modelo de CPU:             Intel Core i7-9700K
Nucleos Logicos:           8
Nucleos Fisicos (est.):    8
Cache L1:                  32.00 KB
Cache L2:                  256.00 KB
Cache L3:                  12.00 MB
Tamanio de bloque optimo:  64x64
========================================
```

### Tabla de Benchmark Completo

```
========================================
    TABLA PARALELA - COMPARACION
========================================
| Procesos   | Tiempo (s)   | Speedup Exp | Speedup Amdahl | Eficiencia   | Granularidad |
| 1          | 2.345600     | 1.00x       | 1.00x          | 100.0%       | N/A          |
| 2          | 1.210300     | 1.94x       | 1.96x          | 97.0%        | Gruesa       |
| 4          | 0.645200     | 3.64x       | 3.77x          | 91.0%        | Media        |
| 8          | 0.312100     | 7.52x       | 7.02x          | 94.0%        | Fina         |
========================================

========================================
    FRACCION PARALELIZABLE (f)
========================================
f (teorico asumido):       0.980 (98.0% paralelizable)
f (empirico medido):       0.973 (97.3% paralelizable)
Metodo usado:              Calculado de S(2) experimental
========================================

========================================
    ANALISIS FINAL
========================================
Mejor speedup observado:        7.52x con 8 procesos
Speedup maximo teorico (Amdahl): 37.04x (P->infinito)
Limitacion por codigo secuencial: 2.7%
========================================
```

## üßÆ Conceptos T√©cnicos

### Optimizaci√≥n por Bloques (Blocking/Tiling)

En lugar de multiplicar matrices elemento por elemento:

```
C[i][j] = Œ£ A[i][k] * B[k][j]
```

Se dividen en bloques peque√±os que caben en cach√© L1:

```
Para cada bloque de C:
  Cargar bloque de A en cach√©
  Cargar bloque de B en cach√©
  Calcular bloque de C
```

**Ventajas:**
- Reduce cache misses de ~90% a ~10%
- Mejora hasta 20x en rendimiento
- Tama√±o de bloque calculado autom√°ticamente seg√∫n cach√© L1

### Ley de Amdahl

La fracci√≥n paralelizable (f) determina el speedup m√°ximo:

```
S(P) = 1 / ((1-f) + f/P)
S_max = 1 / (1-f)
```

**Ejemplo:**
- Si f = 0.95 (95% paralelizable, 5% secuencial)
- Speedup m√°ximo = 1/0.05 = 20x (incluso con infinitos procesos)

El programa calcula **f emp√≠ricamente** usando la medici√≥n con P=2:

```
f = 2 * (1 - 1/S(2))
```

### Granularidad

Indica el balance entre c√≥mputo y comunicaci√≥n:

- **Gruesa** (Eficiencia > 80%): Poco overhead, mucho c√≥mputo
- **Media** (50% < Eficiencia ‚â§ 80%): Balance
- **Fina** (Eficiencia ‚â§ 50%): Mucho overhead, poco c√≥mputo

## üìÅ Estructura del Proyecto

```
proyecto/
‚îú‚îÄ‚îÄ include/
‚îÇ   ‚îú‚îÄ‚îÄ Config.h                # Constantes y estructuras
‚îÇ   ‚îú‚îÄ‚îÄ HardwareDetector.h      # Detecci√≥n de hardware
‚îÇ   ‚îú‚îÄ‚îÄ MatrixMultiplier.h      # Multiplicaci√≥n optimizada
‚îÇ   ‚îú‚îÄ‚îÄ ProcessManager.h        # Gesti√≥n de procesos
‚îÇ   ‚îú‚îÄ‚îÄ PerformanceAnalyzer.h   # An√°lisis de rendimiento
‚îÇ   ‚îú‚îÄ‚îÄ SharedMemory.h          # Memoria compartida (IPC)
‚îÇ   ‚îî‚îÄ‚îÄ Utils.h                 # Utilidades
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.cpp                # Programa principal
‚îÇ   ‚îú‚îÄ‚îÄ HardwareDetector.cpp
‚îÇ   ‚îú‚îÄ‚îÄ MatrixMultiplier.cpp
‚îÇ   ‚îú‚îÄ‚îÄ ProcessManager.cpp
‚îÇ   ‚îú‚îÄ‚îÄ PerformanceAnalyzer.cpp
‚îÇ   ‚îú‚îÄ‚îÄ SharedMemory.cpp
‚îÇ   ‚îî‚îÄ‚îÄ Utils.cpp
‚îÇ
‚îú‚îÄ‚îÄ Makefile                    # Compilaci√≥n (Linux/macOS)
‚îú‚îÄ‚îÄ CMakeLists.txt              # Compilaci√≥n (multiplataforma)
‚îú‚îÄ‚îÄ plot_results.py             # Script Python para graficaci√≥n
‚îú‚îÄ‚îÄ benchmark_results.csv       # Resultados exportados (generado)
‚îî‚îÄ‚îÄ README.md                   # Este archivo
```

## üêõ Soluci√≥n de Problemas

### Error: "No se pudo crear memoria compartida"

**Causa:** L√≠mites del sistema para memoria compartida.

**Soluci√≥n (Linux):**
```bash
# Ver l√≠mites actuales
ipcs -lm

# Aumentar l√≠mite (como root)
sudo sysctl -w kernel.shmmax=1073741824
sudo sysctl -w kernel.shmall=268435456
```

### Error de compilaci√≥n: "pthread.h not found"

**Soluci√≥n:**
```bash
# Ubuntu/Debian
sudo apt-get install build-essential

# macOS (instalar Xcode Command Line Tools)
xcode-select --install
```

### El programa se bloquea en paralelo

**Causa:** Procesos hijos no terminan correctamente.

**Soluci√≥n:** Verificar que no hay procesos zombies:
```bash
ps aux | grep matrix_mult
killall -9 matrix_mult
```

## üìù Notas

- El tama√±o de bloque se calcula autom√°ticamente seg√∫n el cach√© L1 de tu CPU
- En Windows, la implementaci√≥n paralela tiene limitaciones (usa CreateProcess en lugar de fork)
- Para matrices muy grandes (>5000x5000), considera aumentar la memoria compartida del sistema
- Los mejores resultados se obtienen con matrices de tama√±o m√∫ltiplo del tama√±o de bloque

## üë®‚Äçüíª Autor

Proyecto desarrollado para el curso de Programaci√≥n Paralela.

## üìÑ Licencia

Este proyecto es de c√≥digo abierto para fines educativos.
